{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf2ed480b7015889",
   "metadata": {},
   "source": [
    "## **Task 4 : Data Collection and Decision Tree Implement  [4 marks]**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "7d850b4d21ad3aae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T17:10:36.158939Z",
     "start_time": "2024-08-26T17:10:27.567695Z"
    }
   },
   "source": [
    "# Library imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "import warnings\n",
    "\n",
    "from metrics import accuracy\n",
    "\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Give the path of the test and train folder of UCI HAR Dataset\n",
    "train_path = \"./UCI HAR Dataset/train\"\n",
    "test_path = \"./UCI HAR Dataset/test\"\n",
    "\n",
    "# Dictionary of activities. Provided by the dataset.\n",
    "ACTIVITIES = {\n",
    "    1: 'WALKING',\n",
    "    2: 'WALKING_UPSTAIRS',\n",
    "    3: 'WALKING_DOWNSTAIRS',\n",
    "    4: 'SITTING',\n",
    "    5: 'STANDING',\n",
    "    6: 'LAYING',\n",
    "}\n",
    "\n",
    "# =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "# Combining Traing Data\n",
    "# =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "# Load all the accelerometer data\n",
    "total_acc_x = pd.read_csv(os.path.join(train_path, \"Inertial Signals\", \"total_acc_x_train.txt\"), sep='\\\\s+',\n",
    "                          header=None)\n",
    "total_acc_y = pd.read_csv(os.path.join(train_path, \"Inertial Signals\", \"total_acc_y_train.txt\"), sep='\\\\s+',\n",
    "                          header=None)\n",
    "total_acc_z = pd.read_csv(os.path.join(train_path, \"Inertial Signals\", \"total_acc_z_train.txt\"), sep='\\\\s+',\n",
    "                          header=None)\n",
    "\n",
    "# Read the subject IDs\n",
    "subject_train = pd.read_csv(os.path.join(train_path, \"subject_train.txt\"), sep='\\\\s+', header=None)\n",
    "\n",
    "# Read the labels\n",
    "y = pd.read_csv(os.path.join(train_path, \"y_train.txt\"), sep='\\\\s+', header=None)\n",
    "\n",
    "# Toggle through all the subjects.\n",
    "for subject in np.unique(subject_train.values):\n",
    "\n",
    "    sub_idxs = np.where(subject_train.iloc[:, 0] == subject)[0]\n",
    "    labels = y.loc[sub_idxs]\n",
    "\n",
    "    # Toggle through all the labels.\n",
    "    for label in np.unique(labels.values):\n",
    "\n",
    "        # make the folder directory if it does not exist\n",
    "        if not os.path.exists(os.path.join(\"Combined\", \"Train\", ACTIVITIES[label])):\n",
    "            os.makedirs(os.path.join(\"Combined\", \"Train\", ACTIVITIES[label]))\n",
    "\n",
    "        label_idxs = labels[labels.iloc[:, 0] == label].index\n",
    "\n",
    "        accx = []\n",
    "        accy = []\n",
    "        accz = []\n",
    "\n",
    "        for idx in label_idxs:\n",
    "            if accx is not None:\n",
    "                accx = np.hstack((accx, total_acc_x.loc[idx][64:]))\n",
    "                accy = np.hstack((accy, total_acc_y.loc[idx][64:]))\n",
    "                accz = np.hstack((accz, total_acc_z.loc[idx][64:]))\n",
    "\n",
    "            else:\n",
    "                accx = total_acc_x.loc[idx]\n",
    "                accy = total_acc_y.loc[idx]\n",
    "                accz = total_acc_z.loc[idx]\n",
    "\n",
    "        # saving the data into csv file\n",
    "        data = pd.DataFrame({'accx': accx, 'accy': accy, 'accz': accz})\n",
    "        save_path = os.path.join(\"Combined\", \"Train\", ACTIVITIES[label], f\"Subject_{subject}.csv\")\n",
    "        data.to_csv(save_path, index=False)\n",
    "\n",
    "print(\"Done Combining the training data\")\n",
    "\n",
    "# =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "# Combining Test Data\n",
    "# =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "# Load all the accelerometer data\n",
    "total_acc_x = pd.read_csv(os.path.join(test_path, \"Inertial Signals\", \"total_acc_x_test.txt\"), sep='\\\\s+',\n",
    "                          header=None)\n",
    "total_acc_y = pd.read_csv(os.path.join(test_path, \"Inertial Signals\", \"total_acc_y_test.txt\"), sep='\\\\s+',\n",
    "                          header=None)\n",
    "total_acc_z = pd.read_csv(os.path.join(test_path, \"Inertial Signals\", \"total_acc_z_test.txt\"), sep='\\\\s+',\n",
    "                          header=None)\n",
    "\n",
    "# Read the subject IDs\n",
    "subject_test = pd.read_csv(os.path.join(test_path, \"subject_test.txt\"), sep='\\\\s+', header=None)\n",
    "\n",
    "# Read the labels\n",
    "y = pd.read_csv(os.path.join(test_path, \"y_test.txt\"), sep='\\\\s+', header=None)\n",
    "\n",
    "# Toggle through all the subjects.\n",
    "for subject in np.unique(subject_test.values):\n",
    "\n",
    "    sub_idxs = np.where(subject_test.iloc[:, 0] == subject)[0]\n",
    "    labels = y.loc[sub_idxs]\n",
    "\n",
    "    # Toggle through all the labels.\n",
    "    for label in np.unique(labels.values):\n",
    "\n",
    "        if not os.path.exists(os.path.join(\"Combined\", \"Test\", ACTIVITIES[label])):\n",
    "            os.makedirs(os.path.join(\"Combined\", \"Test\", ACTIVITIES[label]))\n",
    "\n",
    "        label_idxs = labels[labels.iloc[:, 0] == label].index\n",
    "\n",
    "        accx = []\n",
    "        accy = []\n",
    "        accz = []\n",
    "        for idx in label_idxs:\n",
    "            if accx is not None:\n",
    "                accx = np.hstack((accx, total_acc_x.loc[idx][64:]))\n",
    "                accy = np.hstack((accy, total_acc_y.loc[idx][64:]))\n",
    "                accz = np.hstack((accz, total_acc_z.loc[idx][64:]))\n",
    "\n",
    "            else:\n",
    "                accx = total_acc_x.loc[idx]\n",
    "                accy = total_acc_y.loc[idx]\n",
    "                accz = total_acc_z.loc[idx]\n",
    "\n",
    "        # saving the data into csv file\n",
    "        data = pd.DataFrame({'accx': accx, 'accy': accy, 'accz': accz})\n",
    "        save_path = os.path.join(\"Combined\", \"Test\", ACTIVITIES[label], f\"Subject_{subject}.csv\")\n",
    "        data.to_csv(save_path, index=False)\n",
    "\n",
    "print(\"Done Combining the testing data\")\n",
    "print(\"Done Combining the data\")\n",
    "\n",
    "# Creation of raw dataset\n",
    "\n",
    "x = pd.read_csv(os.path.join(train_path,\"X_train.txt\"), sep='\\\\s+', header=None)\n",
    "featurel = pd.read_csv(os.path.join(\"./UCI HAR Dataset\",\"features.txt\"), sep='\\\\s+', header=None)\n",
    "featurelist = list(featurel.loc[:,1])\n",
    "x.columns = featurelist\n",
    "yg = pd.read_csv(os.path.join(train_path,\"y_train.txt\"), sep='\\\\s+', header=None)\n",
    "xtest = pd.read_csv(os.path.join(test_path,\"X_test.txt\"), sep='\\\\s+', header=None)\n",
    "xtest.columns = featurelist\n",
    "ytest = pd.read_csv(os.path.join(test_path,\"y_test.txt\"), sep='\\\\s+', header=None)\n",
    "\n",
    "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Combining the training data\n",
      "Done Combining the testing data\n",
      "Done Combining the data\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "2246b715693479a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T17:10:36.712679Z",
     "start_time": "2024-08-26T17:10:36.263333Z"
    }
   },
   "source": [
    "# Library imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "# plt.style.use('dark_background') # for dark background of plts\n",
    "\n",
    "# Constants\n",
    "time = 10\n",
    "offset = 100\n",
    "folders = [\"LAYING\", \"SITTING\", \"STANDING\", \"WALKING\", \"WALKING_DOWNSTAIRS\", \"WALKING_UPSTAIRS\"]\n",
    "classes = {\"WALKING\": 1, \"WALKING_UPSTAIRS\": 2, \"WALKING_DOWNSTAIRS\": 3, \"SITTING\": 4, \"STANDING\": 5, \"LAYING\": 6}\n",
    "\n",
    "combined_dir = os.path.join(\"Combined\")\n",
    "\n",
    "# =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "# Train Dataset\n",
    "# =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "dataset_dir = os.path.join(combined_dir, \"Train\")\n",
    "\n",
    "for folder in folders:\n",
    "    files = os.listdir(os.path.join(dataset_dir, folder))\n",
    "\n",
    "    for file in files:\n",
    "        df = pd.read_csv(os.path.join(dataset_dir, folder, file), sep=\",\", header=0)\n",
    "        df = df[offset:offset + time * 50]\n",
    "        X_train.append(df.values)\n",
    "        y_train.append(classes[folder])\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "# Test Dataset\n",
    "# =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "dataset_dir = os.path.join(combined_dir, \"Test\")\n",
    "\n",
    "for folder in folders:\n",
    "    files = os.listdir(os.path.join(dataset_dir, folder))\n",
    "    for file in files:\n",
    "        df = pd.read_csv(os.path.join(dataset_dir, folder, file), sep=\",\", header=0)\n",
    "        df = df[offset:offset + time * 50]\n",
    "        X_test.append(df.values)\n",
    "        y_test.append(classes[folder])\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "# Final Dataset\n",
    "# =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "# USE THE BELOW GIVEN DATA FOR TRAINING and TESTING purposes\n",
    "\n",
    "# concatenate the training and testing data\n",
    "X = np.concatenate((X_train, X_test))\n",
    "y = np.concatenate((y_train, y_test))\n",
    "\n",
    "# split the data into training and testing sets. Change the seed value to obtain different random splits.\n",
    "seed = 4\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=seed, stratify=y)\n",
    "\n",
    "print(\"Training data shape: \", X_train.shape)\n",
    "print(\"Testing data shape: \", X_test.shape)\n",
    "\n",
    "# =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (126, 500, 3)\n",
      "Testing data shape:  (54, 500, 3)\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T17:10:36.746457Z",
     "start_time": "2024-08-26T17:10:36.731824Z"
    }
   },
   "cell_type": "code",
   "source": "df = pd.DataFrame(np.concatenate((X_train.reshape((-1, 3)), np.repeat(y_train, 500).reshape(-1,1)), axis = 1), columns = [\"accx\", \"accy\", \"accz\", \"Label\"])",
   "id": "c877c015027e7343",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T17:10:36.830021Z",
     "start_time": "2024-08-26T17:10:36.822064Z"
    }
   },
   "cell_type": "code",
   "source": "df[\"totalacc\"] = df[\"accx\"]**2 + df[\"accy\"]**2 + df[\"accz\"]**2",
   "id": "f0cec4a11af08516",
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "id": "e1a476919367d64c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T17:10:41.798571Z",
     "start_time": "2024-08-26T17:10:37.004450Z"
    }
   },
   "source": [
    "import tsfel\n",
    "\n",
    "cfg = tsfel.get_features_by_domain()\n",
    "features = tsfel.time_series_features_extractor(cfg,df[[\"accx\",\"accy\",\"accz\"]], fs=50, window_size=500)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Feature extraction started ***\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "              <p>\n",
       "                  Progress: 100% Complete\n",
       "              <p/>\n",
       "              <progress\n",
       "                  value='126'\n",
       "                  max='126',\n",
       "                  style='width: 25%',\n",
       "              >\n",
       "                  126\n",
       "              </progress>\n",
       "\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Feature extraction finished ***\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "id": "cbb4e6b339ec0854",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T17:10:42.133165Z",
     "start_time": "2024-08-26T17:10:41.927380Z"
    }
   },
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "d = pd.read_csv(\"./Task4-Data/Processed/Combined.csv\")\n",
    "acc = d[['gFx','gFy','gFz']]\n",
    "dtest = d[\"Label\"]\n",
    "X_train_reshaped = X_train.reshape(-1,1500)\n",
    "acc = acc.to_numpy()\n",
    "acc_reshaped = acc.reshape(18,1500)\n",
    "clf = DecisionTreeClassifier(random_state=2,max_depth=6)\n",
    "clf.fit(X_train_reshaped, y_train)\n",
    "dpred = clf.predict(acc_reshaped)\n",
    "print(f\"Accuracy of author's data trained dataset on our data is {accuracy_score(dtest[::500], dpred)*100:.2f}%\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of author's data trained dataset on our data is 38.89%\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "id": "b507be1aeddd0e16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T17:10:46.554369Z",
     "start_time": "2024-08-26T17:10:42.145053Z"
    }
   },
   "source": [
    "clf = DecisionTreeClassifier(random_state=2,max_depth=8)\n",
    "\n",
    "clf.fit(features, y_train)\n",
    "print(d.columns)\n",
    "d.columns = ['Person','accx','accy','accz','Total acc','Label']\n",
    "dtsfel = tsfel.time_series_features_extractor(cfg,d[[\"accx\",\"accy\",\"accz\"]], fs=50, window_size=500)\n",
    "dpred = clf.predict(dtsfel)\n",
    "print(f\"Accuracy of TSFEL trained decision tree on our data is {accuracy_score(dtest[::500],dpred)*100:.2f}%\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Person', 'gFx', 'gFy', 'gFz', 'TgF', 'Label'], dtype='object')\n",
      "*** Feature extraction started ***\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "              <p>\n",
       "                  Progress: 100% Complete\n",
       "              <p/>\n",
       "              <progress\n",
       "                  value='18'\n",
       "                  max='18',\n",
       "                  style='width: 25%',\n",
       "              >\n",
       "                  18\n",
       "              </progress>\n",
       "\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Feature extraction finished ***\n",
      "Accuracy of TSFEL trained decision tree on our data is 27.78%\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-26T17:10:46.744724Z",
     "start_time": "2024-08-26T17:10:46.718990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train,x_test,y_train,y_test = train_test_split(acc,dtest,test_size=0.3)\n",
    "clf = DecisionTreeClassifier(random_state=2,max_depth=6)\n",
    "clf.fit(X_train,y_train)\n",
    "dpred = clf.predict(x_test)\n",
    "print(f\"Accuracy of the model trained and tested on our data is {accuracy_score(y_test,dpred)*100:.2f}%\")"
   ],
   "id": "33cd03a6d16e74ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model trained and tested on our data is 78.48%\n"
     ]
    }
   ],
   "execution_count": 37
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
