{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf2ed480b7015889",
   "metadata": {},
   "source": [
    "## **Task 4 : Data Collection and Decision Tree Implement  [4 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d850b4d21ad3aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Combining the training data\n",
      "Done Combining the testing data\n",
      "Done Combining the data\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "# Library imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "# Give the path of the test and train folder of UCI HAR Dataset\n",
    "train_path = \"./UCI HAR Dataset/train\"\n",
    "test_path = \"./UCI HAR Dataset/test\"\n",
    "\n",
    "# Dictionary of activities. Provided by the dataset.\n",
    "ACTIVITIES = {\n",
    "    1: 'WALKING',\n",
    "    2: 'WALKING_UPSTAIRS',\n",
    "    3: 'WALKING_DOWNSTAIRS',\n",
    "    4: 'SITTING',\n",
    "    5: 'STANDING',\n",
    "    6: 'LAYING',\n",
    "}\n",
    "\n",
    "# =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "# Combining Traing Data\n",
    "# =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "# Load all the accelerometer data\n",
    "total_acc_x = pd.read_csv(os.path.join(train_path, \"Inertial Signals\", \"total_acc_x_train.txt\"), sep='\\\\s+',\n",
    "                          header=None)\n",
    "total_acc_y = pd.read_csv(os.path.join(train_path, \"Inertial Signals\", \"total_acc_y_train.txt\"), sep='\\\\s+',\n",
    "                          header=None)\n",
    "total_acc_z = pd.read_csv(os.path.join(train_path, \"Inertial Signals\", \"total_acc_z_train.txt\"), sep='\\\\s+',\n",
    "                          header=None)\n",
    "\n",
    "# Read the subject IDs\n",
    "subject_train = pd.read_csv(os.path.join(train_path, \"subject_train.txt\"), sep='\\\\s+', header=None)\n",
    "\n",
    "# Read the labels\n",
    "y = pd.read_csv(os.path.join(train_path, \"y_train.txt\"), sep='\\\\s+', header=None)\n",
    "\n",
    "# Toggle through all the subjects.\n",
    "for subject in np.unique(subject_train.values):\n",
    "\n",
    "    sub_idxs = np.where(subject_train.iloc[:, 0] == subject)[0]\n",
    "    labels = y.loc[sub_idxs]\n",
    "\n",
    "    # Toggle through all the labels.\n",
    "    for label in np.unique(labels.values):\n",
    "\n",
    "        # make the folder directory if it does not exist\n",
    "        if not os.path.exists(os.path.join(\"Combined\", \"Train\", ACTIVITIES[label])):\n",
    "            os.makedirs(os.path.join(\"Combined\", \"Train\", ACTIVITIES[label]))\n",
    "\n",
    "        label_idxs = labels[labels.iloc[:, 0] == label].index\n",
    "\n",
    "        accx = []\n",
    "        accy = []\n",
    "        accz = []\n",
    "\n",
    "        for idx in label_idxs:\n",
    "            if accx is not None:\n",
    "                accx = np.hstack((accx, total_acc_x.loc[idx][64:]))\n",
    "                accy = np.hstack((accy, total_acc_y.loc[idx][64:]))\n",
    "                accz = np.hstack((accz, total_acc_z.loc[idx][64:]))\n",
    "\n",
    "            else:\n",
    "                accx = total_acc_x.loc[idx]\n",
    "                accy = total_acc_y.loc[idx]\n",
    "                accz = total_acc_z.loc[idx]\n",
    "\n",
    "        # saving the data into csv file\n",
    "        data = pd.DataFrame({'accx': accx, 'accy': accy, 'accz': accz})\n",
    "        save_path = os.path.join(\"Combined\", \"Train\", ACTIVITIES[label], f\"Subject_{subject}.csv\")\n",
    "        data.to_csv(save_path, index=False)\n",
    "\n",
    "print(\"Done Combining the training data\")\n",
    "\n",
    "# =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "# Combining Test Data\n",
    "# =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "# Load all the accelerometer data\n",
    "total_acc_x = pd.read_csv(os.path.join(test_path, \"Inertial Signals\", \"total_acc_x_test.txt\"), sep='\\\\s+',\n",
    "                          header=None)\n",
    "total_acc_y = pd.read_csv(os.path.join(test_path, \"Inertial Signals\", \"total_acc_y_test.txt\"), sep='\\\\s+',\n",
    "                          header=None)\n",
    "total_acc_z = pd.read_csv(os.path.join(test_path, \"Inertial Signals\", \"total_acc_z_test.txt\"), sep='\\\\s+',\n",
    "                          header=None)\n",
    "\n",
    "# Read the subject IDs\n",
    "subject_test = pd.read_csv(os.path.join(test_path, \"subject_test.txt\"), sep='\\\\s+', header=None)\n",
    "\n",
    "# Read the labels\n",
    "y = pd.read_csv(os.path.join(test_path, \"y_test.txt\"), sep='\\\\s+', header=None)\n",
    "\n",
    "# Toggle through all the subjects.\n",
    "for subject in np.unique(subject_test.values):\n",
    "\n",
    "    sub_idxs = np.where(subject_test.iloc[:, 0] == subject)[0]\n",
    "    labels = y.loc[sub_idxs]\n",
    "\n",
    "    # Toggle through all the labels.\n",
    "    for label in np.unique(labels.values):\n",
    "\n",
    "        if not os.path.exists(os.path.join(\"Combined\", \"Test\", ACTIVITIES[label])):\n",
    "            os.makedirs(os.path.join(\"Combined\", \"Test\", ACTIVITIES[label]))\n",
    "\n",
    "        label_idxs = labels[labels.iloc[:, 0] == label].index\n",
    "\n",
    "        accx = []\n",
    "        accy = []\n",
    "        accz = []\n",
    "        for idx in label_idxs:\n",
    "            if accx is not None:\n",
    "                accx = np.hstack((accx, total_acc_x.loc[idx][64:]))\n",
    "                accy = np.hstack((accy, total_acc_y.loc[idx][64:]))\n",
    "                accz = np.hstack((accz, total_acc_z.loc[idx][64:]))\n",
    "\n",
    "            else:\n",
    "                accx = total_acc_x.loc[idx]\n",
    "                accy = total_acc_y.loc[idx]\n",
    "                accz = total_acc_z.loc[idx]\n",
    "\n",
    "        # saving the data into csv file\n",
    "        data = pd.DataFrame({'accx': accx, 'accy': accy, 'accz': accz})\n",
    "        save_path = os.path.join(\"Combined\", \"Test\", ACTIVITIES[label], f\"Subject_{subject}.csv\")\n",
    "        data.to_csv(save_path, index=False)\n",
    "\n",
    "print(\"Done Combining the testing data\")\n",
    "print(\"Done Combining the data\")\n",
    "\n",
    "# Creation of raw dataset\n",
    "\n",
    "x = pd.read_csv(os.path.join(train_path,\"X_train.txt\"), sep='\\\\s+', header=None)\n",
    "featurel = pd.read_csv(os.path.join(\"./UCI HAR Dataset\",\"features.txt\"), sep='\\\\s+', header=None)\n",
    "featurelist = list(featurel.loc[:,1])\n",
    "x.columns = featurelist\n",
    "yg = pd.read_csv(os.path.join(train_path,\"y_train.txt\"), sep='\\\\s+', header=None)\n",
    "xtest = pd.read_csv(os.path.join(test_path,\"X_test.txt\"), sep='\\\\s+', header=None)\n",
    "xtest.columns = featurelist\n",
    "ytest = pd.read_csv(os.path.join(test_path,\"y_test.txt\"), sep='\\\\s+', header=None)\n",
    "\n",
    "# -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2246b715693479a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (126, 500, 3)\n",
      "Testing data shape:  (54, 500, 3)\n"
     ]
    }
   ],
   "source": [
    "# Library imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "# plt.style.use('dark_background') # for dark background of plts\n",
    "\n",
    "# Constants\n",
    "time = 10\n",
    "offset = 100\n",
    "folders = [\"LAYING\", \"SITTING\", \"STANDING\", \"WALKING\", \"WALKING_DOWNSTAIRS\", \"WALKING_UPSTAIRS\"]\n",
    "classes = {\"WALKING\": 1, \"WALKING_UPSTAIRS\": 2, \"WALKING_DOWNSTAIRS\": 3, \"SITTING\": 4, \"STANDING\": 5, \"LAYING\": 6}\n",
    "\n",
    "combined_dir = os.path.join(\"Combined\")\n",
    "\n",
    "# =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "# Train Dataset\n",
    "# =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "dataset_dir = os.path.join(combined_dir, \"Train\")\n",
    "\n",
    "for folder in folders:\n",
    "    files = os.listdir(os.path.join(dataset_dir, folder))\n",
    "\n",
    "    for file in files:\n",
    "        df = pd.read_csv(os.path.join(dataset_dir, folder, file), sep=\",\", header=0)\n",
    "        df = df[offset:offset + time * 50]\n",
    "        X_train.append(df.values)\n",
    "        y_train.append(classes[folder])\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "# Test Dataset\n",
    "# =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "dataset_dir = os.path.join(combined_dir, \"Test\")\n",
    "\n",
    "for folder in folders:\n",
    "    files = os.listdir(os.path.join(dataset_dir, folder))\n",
    "    for file in files:\n",
    "        df = pd.read_csv(os.path.join(dataset_dir, folder, file), sep=\",\", header=0)\n",
    "        df = df[offset:offset + time * 50]\n",
    "        X_test.append(df.values)\n",
    "        y_test.append(classes[folder])\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "# Final Dataset\n",
    "# =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n",
    "\n",
    "# USE THE BELOW GIVEN DATA FOR TRAINING and TESTING purposes\n",
    "\n",
    "# concatenate the training and testing data\n",
    "X = np.concatenate((X_train, X_test))\n",
    "y = np.concatenate((y_train, y_test))\n",
    "\n",
    "# split the data into training and testing sets. Change the seed value to obtain different random splits.\n",
    "seed = 4\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=seed, stratify=y)\n",
    "\n",
    "print(\"Training data shape: \", X_train.shape)\n",
    "print(\"Testing data shape: \", X_test.shape)\n",
    "\n",
    "# =-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-==-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c877c015027e7343",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.concatenate((X_train.reshape((-1, 3)), np.repeat(y_train, 500).reshape(-1,1)), axis = 1), columns = [\"accx\", \"accy\", \"accz\", \"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0cec4a11af08516",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"totalacc\"] = df[\"accx\"]**2 + df[\"accy\"]**2 + df[\"accz\"]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1a476919367d64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Feature extraction started ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "              <p>\n",
       "                  Progress: 100% Complete\n",
       "              <p/>\n",
       "              <progress\n",
       "                  value='126'\n",
       "                  max='126',\n",
       "                  style='width: 25%',\n",
       "              >\n",
       "                  126\n",
       "              </progress>\n",
       "\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Feature extraction finished ***\n"
     ]
    }
   ],
   "source": [
    "import tsfel\n",
    "\n",
    "cfg = tsfel.get_features_by_domain()\n",
    "features = tsfel.time_series_features_extractor(cfg,df[[\"accx\",\"accy\",\"accz\"]], fs=50, window_size=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10768a28",
   "metadata": {},
   "source": [
    "### 1. Use the Decision Tree model trained on the UCI-HAR dataset to predict the activities that you performed. Report the accuracy, precision, recall and confusion matrix of the model. You have three version of UCI dataset you can use a)Raw data from accelerometer, b)TSFEL featurised data, c)Features provided by author. Choose which version to use, ensuring that your test data is similar to your training data. How did the model perform? [1 marks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbb4e6b339ec0854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of author's raw data trained decision tree on our data is 38.89%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "d = pd.read_csv(\"./Task4-Data/Processed/Combined.csv\")\n",
    "acc = d[['gFx','gFy','gFz']]\n",
    "dtest = d[\"Label\"]\n",
    "X_train_reshaped = X_train.reshape(-1,1500)\n",
    "acc = acc.to_numpy()\n",
    "acc_reshaped = acc.reshape(18,1500)\n",
    "clf = DecisionTreeClassifier(random_state=2,max_depth=6)\n",
    "clf.fit(X_train_reshaped, y_train)\n",
    "dpred = clf.predict(acc_reshaped)\n",
    "print(f\"Accuracy of author's raw data trained decision tree on our data is {accuracy_score(dtest[::500], dpred)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b507be1aeddd0e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Person', 'gFx', 'gFy', 'gFz', 'TgF', 'Label'], dtype='object')\n",
      "*** Feature extraction started ***\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "              <p>\n",
       "                  Progress: 100% Complete\n",
       "              <p/>\n",
       "              <progress\n",
       "                  value='18'\n",
       "                  max='18',\n",
       "                  style='width: 25%',\n",
       "              >\n",
       "                  18\n",
       "              </progress>\n",
       "\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Feature extraction finished ***\n",
      "Accuracy of TSFEL trained decision tree on our data is 27.78%\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(random_state=2,max_depth=8)\n",
    "\n",
    "clf.fit(features, y_train)\n",
    "print(d.columns)\n",
    "d.columns = ['Person','accx','accy','accz','Total acc','Label']\n",
    "dtsfel = tsfel.time_series_features_extractor(cfg,d[[\"accx\",\"accy\",\"accz\"]], fs=50, window_size=500)\n",
    "dpred = clf.predict(dtsfel)\n",
    "print(f\"Accuracy of TSFEL trained decision tree on our data is {accuracy_score(dtest[::500],dpred)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dd25f9",
   "metadata": {},
   "source": [
    "> We cant use author's featurized data as we dont have the same features of data from our recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cd03a6d16e74ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model trained and tested on our data is 78.48%\n"
     ]
    }
   ],
   "source": [
    "X_train,x_test,y_train,y_test = train_test_split(acc,dtest,test_size=0.3)\n",
    "clf = DecisionTreeClassifier(random_state=2,max_depth=6)\n",
    "clf.fit(X_train,y_train)\n",
    "dpred = clf.predict(x_test)\n",
    "print(f\"Accuracy of the model trained and tested on our data is {accuracy_score(y_test,dpred)*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
